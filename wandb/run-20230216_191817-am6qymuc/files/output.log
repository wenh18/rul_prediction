
(79923, 100, 13) (79923, 3) (220, 100, 13) (220, 3)
training epoch: 0
step: 0 train loss: 0.020461714 0.020461714
step: 50 train loss: 0.015068835 0.021425724
step: 100 train loss: 0.010854812 0.019618087
step: 150 train loss: 0.011890135 0.01835689
step: 200 train loss: 0.014596006 0.017705776
step: 250 train loss: 0.02258938 0.017143052
step: 300 train loss: 0.0146174785 0.016667597
step: 350 train loss: 0.017228577 0.016465055
step: 400 train loss: 0.017288368 0.016285112
step: 450 train loss: 0.014064846 0.01602643
step: 500 train loss: 0.016151484 0.01596546
step: 550 train loss: 0.008633962 0.01585095
step: 600 train loss: 0.011869678 0.015700897
step: 650 train loss: 0.01628467 0.015590427
step: 700 train loss: 0.011154007 0.015519141
step: 750 train loss: 0.00735102 0.015394162
step: 800 train loss: 0.017902005 0.015286248
step: 850 train loss: 0.0190132 0.01514249
step: 900 train loss: 0.0074889003 0.015007536
step: 950 train loss: 0.017688703 0.014926875
step: 1000 train loss: 0.014571998 0.014849644
step: 1050 train loss: 0.013970698 0.014810374
step: 1100 train loss: 0.017306155 0.014753908
step: 1150 train loss: 0.011370863 0.014631389
step: 1200 train loss: 0.016652184 0.014593199
step: 1250 train loss: 0.011495936 0.01447824
step: 1300 train loss: 0.016038967 0.014432718
step: 1350 train loss: 0.0111867385 0.014380579
step: 1400 train loss: 0.012896521 0.0142909
step: 1450 train loss: 0.008973805 0.014219514
step: 1500 train loss: 0.0121838 0.0141842235
step: 1550 train loss: 0.0059607113 0.014118353
step: 1600 train loss: 0.010092319 0.014050729
step: 1650 train loss: 0.016159393 0.014030533
step: 1700 train loss: 0.010263669 0.014012625
step: 1750 train loss: 0.012466955 0.013950611
step: 1800 train loss: 0.01492774 0.013896579
step: 1850 train loss: 0.009618437 0.013856836
step: 1900 train loss: 0.014981952 0.013833266
step: 1950 train loss: 0.009044901 0.013819413
step: 2000 train loss: 0.017877633 0.013787472
step: 2050 train loss: 0.008123707 0.013751068
step: 2100 train loss: 0.020596901 0.013789373
step: 2150 train loss: 0.01828597 0.0138393575
step: 2200 train loss: 0.011189729 0.01383211
step: 2250 train loss: 0.010160894 0.013793254
step: 2300 train loss: 0.013551745 0.01375483
step: 2350 train loss: 0.008930689 0.013756481
step: 2400 train loss: 0.013614807 0.013746847
step: 2450 train loss: 0.012400238 0.013729276
started to evaluate
ratio 0
ratio 1
ratio 2
ratio 3
tensor([[0.6373]], device='cuda:0') tensor(0.5447)
tensor([[0.6175]], device='cuda:0') tensor(0.8603)
tensor([[0.6659]], device='cuda:0') tensor(0.5890)
error: tensor(0.2576)
tensor(412.9239)
Epoch number :  0
-- "train" loss 0.02244 -- "valid" loss 412.9
training epoch: 1
step: 0 train loss: 0.010433388 0.013718026
step: 50 train loss: 0.011371243 0.013691903
step: 100 train loss: 0.010601902 0.013660813
step: 150 train loss: 0.012776676 0.013629189
step: 200 train loss: 0.0106283715 0.013603999
step: 250 train loss: 0.012513933 0.0135857705
step: 300 train loss: 0.007660555 0.013612267
step: 350 train loss: 0.014724757 0.013591329
step: 400 train loss: 0.023126151 0.013570195
step: 450 train loss: 0.008550705 0.013543107
step: 500 train loss: 0.016908504 0.013576048
step: 550 train loss: 0.011025598 0.013615624
step: 600 train loss: 0.011078178 0.013648107
step: 650 train loss: 0.020030133 0.013660604
step: 700 train loss: 0.016398257 0.0136612905
step: 750 train loss: 0.015178114 0.013648181
step: 800 train loss: 0.01185445 0.013623949
step: 850 train loss: 0.011369753 0.013593055
step: 900 train loss: 0.013579987 0.013568271
step: 950 train loss: 0.014122012 0.013541097
step: 1000 train loss: 0.01565673 0.013515446
step: 1050 train loss: 0.015681272 0.013486979
step: 1100 train loss: 0.010937281 0.013449806
step: 1150 train loss: 0.010096701 0.0134338355
step: 1200 train loss: 0.0125809135 0.013416705
step: 1250 train loss: 0.007704665 0.013410228
step: 1300 train loss: 0.014096868 0.01339457
step: 1350 train loss: 0.018327085 0.013377822
step: 1400 train loss: 0.010993644 0.013361654
step: 1450 train loss: 0.008998454 0.013339634
step: 1500 train loss: 0.009985586 0.013327739
step: 1550 train loss: 0.012416915 0.013302844
step: 1600 train loss: 0.011482781 0.013294427
step: 1650 train loss: 0.011766117 0.013268194
step: 1700 train loss: 0.011379878 0.013251479
step: 1750 train loss: 0.008839603 0.013228893
step: 1800 train loss: 0.0106804855 0.013239639
step: 1850 train loss: 0.022608338 0.013311151
step: 1900 train loss: 0.019916456 0.013376288
step: 1950 train loss: 0.020206114 0.013437361
step: 2000 train loss: 0.01913961 0.013487001
step: 2050 train loss: 0.016865768 0.013527867
step: 2100 train loss: 0.012951225 0.013546832
step: 2150 train loss: 0.0115429135 0.013561509
step: 2200 train loss: 0.011628478 0.013587664
step: 2250 train loss: 0.007353922 0.013592545
step: 2300 train loss: 0.016678901 0.013595428
step: 2350 train loss: 0.011299824 0.013595339
step: 2400 train loss: 0.014372267 0.013592491
step: 2450 train loss: 0.016195655 0.013593638
started to evaluate
ratio 0
ratio 1
ratio 2
ratio 3
tensor([[0.6156]], device='cuda:0') tensor(0.5447)
tensor([[0.5214]], device='cuda:0') tensor(0.8603)
tensor([[0.5507]], device='cuda:0') tensor(0.5890)
error: tensor(0.2108)
tensor(371.2864)
Epoch number :  1
-- "train" loss 0.01542 -- "valid" loss 371.3
training epoch: 2
step: 0 train loss: 0.00845677 0.0135871535
step: 50 train loss: 0.015341418 0.013584187
step: 100 train loss: 0.011141241 0.0135833835
step: 150 train loss: 0.02085951 0.013573646
step: 200 train loss: 0.017192256 0.013561158
step: 250 train loss: 0.007177002 0.013556781
step: 300 train loss: 0.012725459 0.013550845
step: 350 train loss: 0.010952433 0.013537317
step: 400 train loss: 0.0065624057 0.013526842
step: 450 train loss: 0.020295553 0.013512044
step: 500 train loss: 0.011192452 0.013496959
step: 550 train loss: 0.015237847 0.013481793
step: 600 train loss: 0.007501872 0.013468069
step: 650 train loss: 0.0136850495 0.013464389
step: 700 train loss: 0.006836311 0.01347614
step: 750 train loss: 0.010390671 0.013488137
step: 800 train loss: 0.009658411 0.013473211
step: 850 train loss: 0.016775556 0.013452171
step: 900 train loss: 0.010081876 0.013431131
step: 950 train loss: 0.018809164 0.013415403
step: 1000 train loss: 0.011008469 0.013404551
step: 1050 train loss: 0.0118467435 0.013392518
step: 1100 train loss: 0.01108975 0.013377303
step: 1150 train loss: 0.018064111 0.013364793
step: 1200 train loss: 0.0131163085 0.013349569
step: 1250 train loss: 0.0075097363 0.013334064
step: 1300 train loss: 0.015647165 0.013323394
step: 1350 train loss: 0.0108664995 0.013311259
step: 1400 train loss: 0.012099323 0.013304031
step: 1450 train loss: 0.011083108 0.013295986
step: 1500 train loss: 0.01174716 0.013287388
step: 1550 train loss: 0.011999889 0.013274999
step: 1600 train loss: 0.014691666 0.013262825
step: 1650 train loss: 0.010238036 0.013251672
step: 1700 train loss: 0.009364632 0.01323276
step: 1750 train loss: 0.016146148 0.013218006
step: 1800 train loss: 0.017783748 0.013204186
step: 1850 train loss: 0.010571519 0.013197553
step: 1900 train loss: 0.012928653 0.013185468
step: 1950 train loss: 0.011443216 0.013176441
step: 2000 train loss: 0.01122735 0.013159047
step: 2050 train loss: 0.010436331 0.013151888
step: 2100 train loss: 0.0084292 0.01314339
step: 2150 train loss: 0.013570787 0.01313157
step: 2200 train loss: 0.012765998 0.013120443
step: 2250 train loss: 0.007206196 0.013106904
step: 2300 train loss: 0.011756418 0.013095527
step: 2350 train loss: 0.010423345 0.013077326
step: 2400 train loss: 0.010294762 0.013063829
step: 2450 train loss: 0.009148033 0.0130481515
started to evaluate
ratio 0
ratio 1
ratio 2
ratio 3
tensor([[0.6665]], device='cuda:0') tensor(0.5447)
tensor([[0.6577]], device='cuda:0') tensor(0.8603)
tensor([[0.5310]], device='cuda:0') tensor(0.5890)
error: tensor(0.1735)
tensor(307.5569)
Epoch number :  2
-- "train" loss 0.008493 -- "valid" loss 307.6
training epoch: 3
step: 0 train loss: 0.0059104683 0.0130427405
step: 50 train loss: 0.0085846195 0.013031995
step: 100 train loss: 0.014124773 0.013022544
step: 150 train loss: 0.011543227 0.01301135
step: 200 train loss: 0.013109769 0.013000023
step: 250 train loss: 0.012291549 0.01299115
step: 300 train loss: 0.012736742 0.012979791
step: 350 train loss: 0.0141142 0.012965176
step: 400 train loss: 0.014507362 0.01295173
step: 450 train loss: 0.0105088465 0.012942791
step: 500 train loss: 0.013449291 0.012931168
step: 550 train loss: 0.009553133 0.012916778
step: 600 train loss: 0.020108562 0.012964215
step: 650 train loss: 0.016874092 0.013009621
step: 700 train loss: 0.019506743 0.013044604
step: 750 train loss: 0.018606467 0.01307292
step: 800 train loss: 0.011333361 0.013087219
step: 850 train loss: 0.009700234 0.013094799
step: 900 train loss: 0.018892076 0.0131045235
step: 950 train loss: 0.017263375 0.013112542
step: 1000 train loss: 0.0137376515 0.0131162
step: 1050 train loss: 0.006123051 0.013116931
step: 1100 train loss: 0.008955052 0.013111741
step: 1150 train loss: 0.01365039 0.0131084025
step: 1200 train loss: 0.010921434 0.013103195
step: 1250 train loss: 0.009774881 0.013098932
step: 1300 train loss: 0.013556166 0.013089198
step: 1350 train loss: 0.016558943 0.013087321
step: 1400 train loss: 0.0096251685 0.013085266
step: 1450 train loss: 0.008867544 0.013082632
step: 1500 train loss: 0.009445821 0.013075193
step: 1550 train loss: 0.011957196 0.013063926
step: 1600 train loss: 0.00965428 0.013055615
step: 1650 train loss: 0.0085678715 0.013047597
step: 1700 train loss: 0.008702771 0.01304488
step: 1750 train loss: 0.0108541185 0.013036129
step: 1800 train loss: 0.015029639 0.01303435
step: 1850 train loss: 0.0056074173 0.013022576
step: 1900 train loss: 0.010293557 0.013016492
step: 1950 train loss: 0.008295684 0.013010898
step: 2000 train loss: 0.0076306313 0.013000842
step: 2050 train loss: 0.0137255555 0.012994969
step: 2100 train loss: 0.006763819 0.0129861
step: 2150 train loss: 0.012630842 0.0129754385
step: 2200 train loss: 0.009973689 0.012970654
step: 2250 train loss: 0.009510983 0.012964113
step: 2300 train loss: 0.0076485155 0.012957066
step: 2350 train loss: 0.019277204 0.012955612
step: 2400 train loss: 0.009432742 0.012945865
step: 2450 train loss: 0.016310478 0.012936517
started to evaluate
ratio 0
ratio 1
ratio 2
ratio 3
tensor([[0.8424]], device='cuda:0') tensor(0.5447)
tensor([[0.6394]], device='cuda:0') tensor(0.8603)
tensor([[0.6717]], device='cuda:0') tensor(0.5890)
error: tensor(0.2826)
tensor(468.8413)
Epoch number :  3
-- "train" loss 0.008151 -- "valid" loss 468.8
training epoch: 4
step: 0 train loss: 0.013481779 0.012927924
step: 50 train loss: 0.013550272 0.012917175
step: 100 train loss: 0.019963382 0.012913861
step: 150 train loss: 0.008966788 0.012902468
step: 200 train loss: 0.008765179 0.012892316
step: 250 train loss: 0.010787537 0.012883792
step: 300 train loss: 0.008584848 0.012873781
step: 350 train loss: 0.011909832 0.012864342
step: 400 train loss: 0.012557289 0.012854582
step: 450 train loss: 0.009942663 0.012843929
step: 500 train loss: 0.009799017 0.012837071
step: 550 train loss: 0.013247398 0.01283306
step: 600 train loss: 0.014342592 0.012838016
step: 650 train loss: 0.015538465 0.012844061
step: 700 train loss: 0.009977269 0.012838455
step: 750 train loss: 0.011565626 0.012828871
step: 800 train loss: 0.011708237 0.012822626
step: 850 train loss: 0.012010674 0.012813407
step: 900 train loss: 0.012537839 0.012803784
step: 950 train loss: 0.01462815 0.0127951745
step: 1000 train loss: 0.021964028 0.012790239
step: 1050 train loss: 0.0146494415 0.01278002
step: 1100 train loss: 0.016436791 0.012770865
step: 1150 train loss: 0.014973854 0.01276065
step: 1200 train loss: 0.016856061 0.012755407
step: 1250 train loss: 0.008471576 0.012747072
step: 1300 train loss: 0.009973904 0.012737774
step: 1350 train loss: 0.011234473 0.012726707
step: 1400 train loss: 0.011575301 0.012719957
step: 1450 train loss: 0.007985854 0.0127138905
step: 1500 train loss: 0.009164583 0.012706391
step: 1550 train loss: 0.031554766 0.012774175
step: 1600 train loss: 0.020044707 0.01282214
step: 1650 train loss: 0.019242123 0.012862298
step: 1700 train loss: 0.020529708 0.0129070915
step: 1750 train loss: 0.027669694 0.012950326
step: 1800 train loss: 0.022931883 0.012998354
step: 1850 train loss: 0.02728119 0.013033886
step: 1900 train loss: 0.018214058 0.013084149
step: 1950 train loss: 0.017377518 0.013117135
step: 2000 train loss: 0.020916866 0.013154445
step: 2050 train loss: 0.017565979 0.013187633
step: 2100 train loss: 0.021873387 0.013226724
step: 2150 train loss: 0.01837453 0.013258941
step: 2200 train loss: 0.025733288 0.01329079
step: 2250 train loss: 0.028402928 0.013324061
step: 2300 train loss: 0.036784198 0.013374661
step: 2350 train loss: 0.023727447 0.013419306
step: 2400 train loss: 0.022418393 0.013459226
step: 2450 train loss: 0.0159148 0.013498295
started to evaluate
ratio 0
ratio 1
ratio 2
ratio 3
tensor([[0.5443]], device='cuda:0') tensor(0.5447)
tensor([[0.5517]], device='cuda:0') tensor(0.8603)
tensor([[0.5604]], device='cuda:0') tensor(0.5890)
error: tensor(0.1724)
tensor(319.0567)
Epoch number :  4
-- "train" loss 0.03445 -- "valid" loss 319.1
training epoch: 5
step: 0 train loss: 0.023612004 0.013531732
step: 50 train loss: 0.01871023 0.013565497
step: 100 train loss: 0.030975295 0.013595614
step: 150 train loss: 0.015566355 0.013623094
step: 200 train loss: 0.016394414 0.01364929
step: 250 train loss: 0.01603377 0.013677307
step: 300 train loss: 0.01927775 0.013707714
step: 350 train loss: 0.014676048 0.013734821
step: 400 train loss: 0.021340473 0.013761983
step: 450 train loss: 0.03126825 0.01378584
step: 500 train loss: 0.017694077 0.013807238
step: 550 train loss: 0.017172726 0.013833171
step: 600 train loss: 0.023517013 0.013864476
step: 650 train loss: 0.014222284 0.0138864685
step: 700 train loss: 0.024483263 0.013916847
step: 750 train loss: 0.017829973 0.013958378
step: 800 train loss: 0.023229927 0.013989927
step: 850 train loss: 0.014525455 0.014021878
step: 900 train loss: 0.021318017 0.014049679
step: 950 train loss: 0.03517859 0.014076405
step: 1000 train loss: 0.030854285 0.014137322
step: 1050 train loss: 0.03045814 0.014198723
step: 1100 train loss: 0.04073255 0.014267265
step: 1150 train loss: 0.021279199 0.0143398475
step: 1200 train loss: 0.03466074 0.014408333
step: 1250 train loss: 0.039994135 0.014477392
step: 1300 train loss: 0.02657242 0.014544059
step: 1350 train loss: 0.029304767 0.014603866
step: 1400 train loss: 0.019843047 0.014648334
step: 1450 train loss: 0.032444313 0.014677261
step: 1500 train loss: 0.019674914 0.014702218
step: 1550 train loss: 0.021050673 0.014724089
step: 1600 train loss: 0.015832355 0.014736458
step: 1650 train loss: 0.019408733 0.014748711
step: 1700 train loss: 0.01413534 0.014761072
step: 1750 train loss: 0.015566076 0.014773183
step: 1800 train loss: 0.015218787 0.014783856
step: 1850 train loss: 0.022924013 0.014796486
step: 1900 train loss: 0.018931072 0.014802904
step: 1950 train loss: 0.015344082 0.014810797
step: 2000 train loss: 0.013140296 0.01481957
step: 2050 train loss: 0.013659116 0.014823784
step: 2100 train loss: 0.019189319 0.0148285935
step: 2150 train loss: 0.017010339 0.014834778
step: 2200 train loss: 0.016840817 0.014838621
step: 2250 train loss: 0.020843707 0.014842217
step: 2300 train loss: 0.017485661 0.014845064
step: 2350 train loss: 0.014371167 0.014847669
step: 2400 train loss: 0.014331813 0.014851506
step: 2450 train loss: 0.016270198 0.014855122
started to evaluate
ratio 0
ratio 1
ratio 2
ratio 3
tensor([[0.6274]], device='cuda:0') tensor(0.5447)
tensor([[0.6050]], device='cuda:0') tensor(0.8603)
tensor([[0.6028]], device='cuda:0') tensor(0.5890)
error: tensor(0.1789)
tensor(324.8360)
Epoch number :  5
-- "train" loss 0.01587 -- "valid" loss 324.8
training epoch: 6
step: 0 train loss: 0.012891382 0.0148589695
step: 50 train loss: 0.017938012 0.014862142
step: 100 train loss: 0.016319875 0.01486131
step: 150 train loss: 0.017642159 0.0148634855
step: 200 train loss: 0.012551891 0.014864178
step: 250 train loss: 0.014863669 0.0148699945
step: 300 train loss: 0.014901097 0.0148717435
step: 350 train loss: 0.01964918 0.014871759
step: 400 train loss: 0.019862045 0.0148736695
step: 450 train loss: 0.010759016 0.014872964
step: 500 train loss: 0.0155307315 0.014870356
step: 550 train loss: 0.0153586045 0.014872235
step: 600 train loss: 0.007999885 0.014874256
step: 650 train loss: 0.015219732 0.0148709975
step: 700 train loss: 0.016114289 0.014870204
step: 750 train loss: 0.007253573 0.014865766
step: 800 train loss: 0.014224093 0.0148660075
step: 850 train loss: 0.0107238395 0.014864363
step: 900 train loss: 0.020680783 0.014861227
step: 950 train loss: 0.00939877 0.014860546
step: 1000 train loss: 0.019903034 0.014856775
step: 1050 train loss: 0.011398193 0.014855592
step: 1100 train loss: 0.008373804 0.0148533955
step: 1150 train loss: 0.007680269 0.014849533
step: 1200 train loss: 0.014685399 0.01484511
step: 1250 train loss: 0.013875568 0.014842959
step: 1300 train loss: 0.008639368 0.014839282
step: 1350 train loss: 0.010444259 0.014836543
step: 1400 train loss: 0.011794645 0.014833893
step: 1450 train loss: 0.019404376 0.014830568
step: 1500 train loss: 0.01310487 0.014825383
step: 1550 train loss: 0.008144143 0.0148201585
step: 1600 train loss: 0.010780231 0.014814637
step: 1650 train loss: 0.010169452 0.014809359
step: 1700 train loss: 0.018249169 0.014802582
step: 1750 train loss: 0.011254211 0.014798643
step: 1800 train loss: 0.011870142 0.014794865
step: 1850 train loss: 0.012843777 0.014792049
step: 1900 train loss: 0.012218621 0.014784798
step: 1950 train loss: 0.019776812 0.014780415
step: 2000 train loss: 0.011850774 0.014775169
step: 2050 train loss: 0.006478778 0.0147681
step: 2100 train loss: 0.010220399 0.014762944
step: 2150 train loss: 0.012070402 0.014758911
step: 2200 train loss: 0.013693701 0.014751105
step: 2250 train loss: 0.011040609 0.014749554
step: 2300 train loss: 0.010202002 0.014743638
step: 2350 train loss: 0.02013668 0.014738287
step: 2400 train loss: 0.012029337 0.014731509
step: 2450 train loss: 0.014180487 0.014726928
started to evaluate
ratio 0
ratio 1
ratio 2
ratio 3
tensor([[0.5743]], device='cuda:0') tensor(0.5447)
tensor([[0.6225]], device='cuda:0') tensor(0.8603)
tensor([[0.5804]], device='cuda:0') tensor(0.5890)
error: tensor(0.1812)
tensor(314.0683)
Epoch number :  6
-- "train" loss 0.008711 -- "valid" loss 314.1
training epoch: 7
step: 0 train loss: 0.017606158 0.01472127
step: 50 train loss: 0.0141213825 0.0147149
step: 100 train loss: 0.0162511 0.014709976
step: 150 train loss: 0.013307039 0.014705251
step: 200 train loss: 0.013100293 0.014699488
step: 250 train loss: 0.0084481165 0.014693108
step: 300 train loss: 0.012130154 0.014687425
step: 350 train loss: 0.011871386 0.014680794
step: 400 train loss: 0.012506938 0.014675947
step: 450 train loss: 0.012870442 0.014669519
step: 500 train loss: 0.012600966 0.01466433
step: 550 train loss: 0.018258404 0.014657304
step: 600 train loss: 0.016212137 0.014651088
step: 650 train loss: 0.0134186875 0.014642974
step: 700 train loss: 0.014468813 0.014633943
step: 750 train loss: 0.013497179 0.014629481
step: 800 train loss: 0.013481633 0.014621711
step: 850 train loss: 0.0105587905 0.014611742
step: 900 train loss: 0.011490736 0.0146083385
step: 950 train loss: 0.014741292 0.014602992
step: 1000 train loss: 0.021066716 0.014595852
step: 1050 train loss: 0.018427908 0.0145893665
step: 1100 train loss: 0.013615337 0.014581609
step: 1150 train loss: 0.012164359 0.014574449
step: 1200 train loss: 0.006430174 0.014566508
step: 1250 train loss: 0.013646546 0.014559245
step: 1300 train loss: 0.01911313 0.0145532135
step: 1350 train loss: 0.013117247 0.014544911
step: 1400 train loss: 0.012096695 0.014536737
step: 1450 train loss: 0.013347913 0.014529566
step: 1500 train loss: 0.0094337715 0.014523568
step: 1550 train loss: 0.008729096 0.014515282
step: 1600 train loss: 0.011883188 0.014509354
step: 1650 train loss: 0.015438093 0.014501849
step: 1700 train loss: 0.008493156 0.014494733
step: 1750 train loss: 0.009380558 0.014488481
step: 1800 train loss: 0.01492513 0.014482903
step: 1850 train loss: 0.011043272 0.014475484
step: 1900 train loss: 0.009314538 0.014468459
step: 1950 train loss: 0.009689465 0.014460598
step: 2000 train loss: 0.01387795 0.014454438
step: 2050 train loss: 0.011151765 0.014446619
step: 2100 train loss: 0.013362257 0.014438127
step: 2150 train loss: 0.012505389 0.014430836
step: 2200 train loss: 0.012954963 0.014423012
step: 2250 train loss: 0.0134423375 0.01441481
step: 2300 train loss: 0.012281994 0.0144102005
step: 2350 train loss: 0.010722469 0.014404151
step: 2400 train loss: 0.007953779 0.01439664
step: 2450 train loss: 0.009377079 0.014389246
started to evaluate
ratio 0
ratio 1
ratio 2
ratio 3
tensor([[0.6321]], device='cuda:0') tensor(0.5447)
tensor([[0.6732]], device='cuda:0') tensor(0.8603)
tensor([[0.6627]], device='cuda:0') tensor(0.5890)
error: tensor(0.1426)
tensor(259.9158)
Epoch number :  7
-- "train" loss 0.004254 -- "valid" loss 259.9
training epoch: 8
step: 0 train loss: 0.010886069 0.014384719
step: 50 train loss: 0.012592372 0.014378405
step: 100 train loss: 0.013527844 0.014372591
step: 150 train loss: 0.015295876 0.014365854
step: 200 train loss: 0.013757701 0.014358281
step: 250 train loss: 0.013740197 0.014352486
step: 300 train loss: 0.0065859635 0.0143464
step: 350 train loss: 0.012165409 0.014339104
step: 400 train loss: 0.014780003 0.014331235
step: 450 train loss: 0.012032823 0.014323429
step: 500 train loss: 0.012442438 0.014316652
step: 550 train loss: 0.006553075 0.014309414
step: 600 train loss: 0.015291505 0.014301818
step: 650 train loss: 0.011859492 0.014295318
step: 700 train loss: 0.0081489505 0.014287265
step: 750 train loss: 0.019465946 0.014281605
step: 800 train loss: 0.0145014385 0.014273904
step: 850 train loss: 0.010882425 0.014266468
step: 900 train loss: 0.012668685 0.014259637
step: 950 train loss: 0.01189471 0.014253181
step: 1000 train loss: 0.009940462 0.014245389
step: 1050 train loss: 0.01064896 0.014240298
step: 1100 train loss: 0.013455659 0.014232349
step: 1150 train loss: 0.014713055 0.014227779
step: 1200 train loss: 0.018942768 0.014220049
step: 1250 train loss: 0.009831585 0.014211967
step: 1300 train loss: 0.01692704 0.014204717
step: 1350 train loss: 0.0062040538 0.014198797
step: 1400 train loss: 0.012092471 0.014190982
step: 1450 train loss: 0.00819975 0.014183934
step: 1500 train loss: 0.011963206 0.014176517
step: 1550 train loss: 0.0110290665 0.01416666
step: 1600 train loss: 0.010393068 0.014158137
step: 1650 train loss: 0.010070777 0.0141531285
step: 1700 train loss: 0.010861958 0.014146314
step: 1750 train loss: 0.011277195 0.014138977
step: 1800 train loss: 0.010144925 0.014132501
step: 1850 train loss: 0.008525069 0.014123303
step: 1900 train loss: 0.006011173 0.01411393
step: 1950 train loss: 0.016364902 0.014107715
step: 2000 train loss: 0.011315959 0.01410079
step: 2050 train loss: 0.014029886 0.0140934
step: 2100 train loss: 0.011484832 0.014086135
step: 2150 train loss: 0.0067952788 0.014079589
step: 2200 train loss: 0.011480176 0.014073598
step: 2250 train loss: 0.008982098 0.014066549
step: 2300 train loss: 0.009714639 0.014057833
step: 2350 train loss: 0.012922139 0.0140533205
step: 2400 train loss: 0.011542954 0.01405032
step: 2450 train loss: 0.01146537 0.014044193
started to evaluate
ratio 0
ratio 1
ratio 2
ratio 3
tensor([[0.6706]], device='cuda:0') tensor(0.5447)
tensor([[0.6581]], device='cuda:0') tensor(0.8603)
tensor([[0.4504]], device='cuda:0') tensor(0.5890)
error: tensor(0.1789)
tensor(311.0126)
Epoch number :  8
-- "train" loss 0.00736 -- "valid" loss 311.0
training epoch: 9
step: 0 train loss: 0.020877354 0.014037555
step: 50 train loss: 0.008513108 0.014031089
step: 100 train loss: 0.0057572243 0.014023416
step: 150 train loss: 0.016343394 0.0140165845
step: 200 train loss: 0.005857375 0.014009624
step: 250 train loss: 0.016106999 0.014001416
step: 300 train loss: 0.009424739 0.013995451
step: 350 train loss: 0.010994489 0.013987863
step: 400 train loss: 0.007795008 0.013981273
step: 450 train loss: 0.010590403 0.013975801
step: 500 train loss: 0.01506698 0.013968277
step: 550 train loss: 0.009744151 0.01396375
step: 600 train loss: 0.014887201 0.01395863
step: 650 train loss: 0.01193295 0.013952433
step: 700 train loss: 0.01232885 0.013947506
step: 750 train loss: 0.010701964 0.013940261
step: 800 train loss: 0.009526828 0.013932811
step: 850 train loss: 0.0072197122 0.013923733
step: 900 train loss: 0.008909246 0.013916828
step: 950 train loss: 0.012872895 0.013910473
step: 1000 train loss: 0.009919344 0.0139030665
step: 1050 train loss: 0.01071307 0.013895822
step: 1100 train loss: 0.008371647 0.0138882585
step: 1150 train loss: 0.012792303 0.013880476
step: 1200 train loss: 0.009085824 0.013873928
step: 1250 train loss: 0.0049887495 0.013867014
step: 1300 train loss: 0.015775101 0.013862484
step: 1350 train loss: 0.022090705 0.013853859
step: 1400 train loss: 0.014865015 0.013847159
step: 1450 train loss: 0.01213318 0.013840308
step: 1500 train loss: 0.010164508 0.013833193
step: 1550 train loss: 0.010224255 0.013826649
step: 1600 train loss: 0.005639078 0.01381943
step: 1650 train loss: 0.015598765 0.013812691
step: 1700 train loss: 0.0074793412 0.013806827
step: 1750 train loss: 0.009113077 0.013803438
step: 1800 train loss: 0.017244145 0.013796871
step: 1850 train loss: 0.0059604254 0.013790158
step: 1900 train loss: 0.012448243 0.013784028
step: 1950 train loss: 0.008269459 0.013777765
step: 2000 train loss: 0.013266306 0.013770908
step: 2050 train loss: 0.012398572 0.013762686
step: 2100 train loss: 0.009444828 0.01375786
step: 2150 train loss: 0.011715948 0.0137512535
step: 2200 train loss: 0.0122732995 0.013745034
step: 2250 train loss: 0.0058074086 0.013738284
step: 2300 train loss: 0.009809097 0.013731787
step: 2350 train loss: 0.008423835 0.013724933
step: 2400 train loss: 0.009742192 0.013716662
step: 2450 train loss: 0.0092924405 0.013710132
started to evaluate
ratio 0
ratio 1
ratio 2
ratio 3
tensor([[0.7252]], device='cuda:0') tensor(0.5447)
tensor([[0.7156]], device='cuda:0') tensor(0.8603)
tensor([[0.5389]], device='cuda:0') tensor(0.5890)
error: tensor(0.2243)
tensor(366.6412)
Epoch number :  9
-- "train" loss 0.01651 -- "valid" loss 366.6
training epoch: 10
step: 0 train loss: 0.009046758 0.013704038
step: 50 train loss: 0.009528794 0.013699746
step: 100 train loss: 0.010533987 0.013694512
step: 150 train loss: 0.011499507 0.013688055
step: 200 train loss: 0.009064662 0.013681441
step: 250 train loss: 0.010950912 0.013679734
step: 300 train loss: 0.022528285 0.013677329
step: 350 train loss: 0.008841674 0.013686119
step: 400 train loss: 0.017925266 0.01369161
step: 450 train loss: 0.013736923 0.013696991
step: 500 train loss: 0.021860825 0.013700433
step: 550 train loss: 0.0145763885 0.0137007665
step: 600 train loss: 0.0065594437 0.013699544
step: 650 train loss: 0.011598122 0.01370335
step: 700 train loss: 0.012811778 0.013701093
step: 750 train loss: 0.00719753 0.013697499
step: 800 train loss: 0.012728913 0.013692582
step: 850 train loss: 0.011879585 0.013687866
step: 900 train loss: 0.009827014 0.01368338
step: 950 train loss: 0.008055619 0.013677184
step: 1000 train loss: 0.010353858 0.013672143
step: 1050 train loss: 0.009375566 0.013667614
step: 1100 train loss: 0.009022694 0.013662285
step: 1150 train loss: 0.017572919 0.0136559885
step: 1200 train loss: 0.0055211494 0.013650666
step: 1250 train loss: 0.007376827 0.013645366
step: 1300 train loss: 0.010883393 0.013639305
step: 1350 train loss: 0.007484228 0.013631999
step: 1400 train loss: 0.004596448 0.013625882
step: 1450 train loss: 0.013368648 0.01361982
step: 1500 train loss: 0.0103404205 0.0136139095
step: 1550 train loss: 0.009260077 0.013608209
step: 1600 train loss: 0.015039506 0.013600488
step: 1650 train loss: 0.009725508 0.01359339
step: 1700 train loss: 0.01075277 0.013587812
step: 1750 train loss: 0.010498006 0.013580819
step: 1800 train loss: 0.01070143 0.013573646
step: 1850 train loss: 0.012337811 0.013569267
step: 1900 train loss: 0.008701448 0.013562642
step: 1950 train loss: 0.0064871064 0.013556545
step: 2000 train loss: 0.008883814 0.013549458
step: 2050 train loss: 0.010487287 0.013542037
step: 2100 train loss: 0.01391679 0.013536055
step: 2150 train loss: 0.012649042 0.013529957
step: 2200 train loss: 0.012532249 0.013525046
step: 2250 train loss: 0.010790754 0.013519668
step: 2300 train loss: 0.012085394 0.0135145085
step: 2350 train loss: 0.012173141 0.013508789
step: 2400 train loss: 0.008963943 0.013504383
step: 2450 train loss: 0.012484139 0.013500524
started to evaluate
ratio 0
ratio 1
ratio 2
ratio 3
tensor([[0.5796]], device='cuda:0') tensor(0.5447)
tensor([[0.3524]], device='cuda:0') tensor(0.8603)
tensor([[0.6082]], device='cuda:0') tensor(0.5890)
error: tensor(0.2919)
tensor(530.0612)
Epoch number :  10
-- "train" loss 0.01372 -- "valid" loss 530.1
training epoch: 11
step: 0 train loss: 0.03136746 0.013494916
step: 50 train loss: 0.011363477 0.0134935705
step: 100 train loss: 0.016872337 0.013489205
step: 150 train loss: 0.014628186 0.013484358
step: 200 train loss: 0.0077927005 0.013480194
step: 250 train loss: 0.0121092545 0.013476741
step: 300 train loss: 0.00669107 0.0134710185
step: 350 train loss: 0.009339486 0.013465152
step: 400 train loss: 0.015186638 0.013458114
step: 450 train loss: 0.010850337 0.013452821
step: 500 train loss: 0.011044471 0.013446817
step: 550 train loss: 0.008836679 0.013440081
step: 600 train loss: 0.014617758 0.013434484
step: 650 train loss: 0.0076421914 0.013428455
step: 700 train loss: 0.008107157 0.013422562
step: 750 train loss: 0.010149699 0.013417607
step: 800 train loss: 0.014761433 0.013412356
step: 850 train loss: 0.01116628 0.01340738
step: 900 train loss: 0.010133075 0.013400307
step: 950 train loss: 0.013892332 0.013392639
step: 1000 train loss: 0.008340597 0.013386527
step: 1050 train loss: 0.0074659106 0.013380892
step: 1100 train loss: 0.0070513766 0.01337534
step: 1150 train loss: 0.0062935483 0.01336787
step: 1200 train loss: 0.009690172 0.013362821
step: 1250 train loss: 0.013495708 0.013358654
step: 1300 train loss: 0.011930396 0.013352501
step: 1350 train loss: 0.009330453 0.0133465445
step: 1400 train loss: 0.015012612 0.013341118
step: 1450 train loss: 0.007980526 0.013336092
step: 1500 train loss: 0.010673855 0.01333082
step: 1550 train loss: 0.007948238 0.013325831
step: 1600 train loss: 0.006808262 0.013320181
step: 1650 train loss: 0.0055230563 0.013315225
step: 1700 train loss: 0.02216633 0.013310374
step: 1750 train loss: 0.008337593 0.013304638
step: 1800 train loss: 0.006587727 0.013299144
step: 1850 train loss: 0.012468147 0.013294091
step: 1900 train loss: 0.006485123 0.01328861
step: 1950 train loss: 0.0069647757 0.013283397
step: 2000 train loss: 0.008034356 0.013278469
step: 2050 train loss: 0.008972416 0.0132745
step: 2100 train loss: 0.010513496 0.013269332
step: 2150 train loss: 0.015168499 0.013264514
step: 2200 train loss: 0.0080669895 0.0132602975
step: 2250 train loss: 0.0071884417 0.013255006
step: 2300 train loss: 0.011488019 0.013249628
step: 2350 train loss: 0.011936144 0.013244066
step: 2400 train loss: 0.007634479 0.013238487
step: 2450 train loss: 0.0058768233 0.013232327
started to evaluate
ratio 0
ratio 1
ratio 2
ratio 3
tensor([[0.7675]], device='cuda:0') tensor(0.5447)
tensor([[0.7572]], device='cuda:0') tensor(0.8603)
tensor([[0.7262]], device='cuda:0') tensor(0.5890)
error: tensor(0.2422)
tensor(405.9525)
Epoch number :  11
-- "train" loss 0.008325 -- "valid" loss 406.0
training epoch: 12
step: 0 train loss: 0.007192479 0.013228552
step: 50 train loss: 0.013829535 0.0132238455
step: 100 train loss: 0.010723654 0.013220431
step: 150 train loss: 0.012527184 0.01321646
step: 200 train loss: 0.016856905 0.013210755
step: 250 train loss: 0.0077385237 0.013206028
step: 300 train loss: 0.014268215 0.01320151
step: 350 train loss: 0.0068893847 0.013195118
step: 400 train loss: 0.016510244 0.013191956
step: 450 train loss: 0.012926962 0.013186269
step: 500 train loss: 0.016281497 0.013182429
step: 550 train loss: 0.011494787 0.013176535
step: 600 train loss: 0.010750302 0.013171317
step: 650 train loss: 0.010624128 0.013166414
step: 700 train loss: 0.005645618 0.013161648
step: 750 train loss: 0.0110025145 0.013156507
step: 800 train loss: 0.009802607 0.013151463
step: 850 train loss: 0.017571634 0.01314691
step: 900 train loss: 0.01966527 0.013143273
step: 950 train loss: 0.013058802 0.013138392
step: 1000 train loss: 0.008568956 0.013132967
step: 1050 train loss: 0.019507492 0.0131278895
step: 1100 train loss: 0.011490418 0.013124151
step: 1150 train loss: 0.009715012 0.0131192785
step: 1200 train loss: 0.010241403 0.013114996
step: 1250 train loss: 0.011290467 0.013109512
step: 1300 train loss: 0.01157576 0.013105758
step: 1350 train loss: 0.013494029 0.013101223
step: 1400 train loss: 0.0073032216 0.013096277
step: 1450 train loss: 0.0048348513 0.013091255
step: 1500 train loss: 0.010964511 0.0130874235
step: 1550 train loss: 0.0070706396 0.013083209
step: 1600 train loss: 0.00987001 0.01307989
step: 1650 train loss: 0.008314934 0.013077136
step: 1700 train loss: 0.011567525 0.013071312
step: 1750 train loss: 0.011458505 0.013066204
step: 1800 train loss: 0.004506259 0.013061092
step: 1850 train loss: 0.006355865 0.013056148
step: 1900 train loss: 0.0026080648 0.013049543
step: 1950 train loss: 0.011981473 0.01304419
step: 2000 train loss: 0.005192384 0.013040266
step: 2050 train loss: 0.008900385 0.013034817
step: 2100 train loss: 0.007335913 0.013030741
step: 2150 train loss: 0.009971287 0.013026069
step: 2200 train loss: 0.012013484 0.013019248
step: 2250 train loss: 0.014361595 0.013013845
step: 2300 train loss: 0.010312576 0.013010197
step: 2350 train loss: 0.011471675 0.0130047565
step: 2400 train loss: 0.008516081 0.013000068
step: 2450 train loss: 0.008454096 0.012995388
started to evaluate
ratio 0
ratio 1
ratio 2
ratio 3
tensor([[0.8060]], device='cuda:0') tensor(0.5447)
tensor([[0.7237]], device='cuda:0') tensor(0.8603)
tensor([[0.6260]], device='cuda:0') tensor(0.5890)
error: tensor(0.2469)
tensor(410.2380)
Epoch number :  12
-- "train" loss 0.007907 -- "valid" loss 410.2
training epoch: 13
step: 0 train loss: 0.008080975 0.012991594
step: 50 train loss: 0.011137184 0.012987552
step: 100 train loss: 0.013534931 0.012981575
step: 150 train loss: 0.0047081946 0.012975947
step: 200 train loss: 0.009899878 0.012971875
step: 250 train loss: 0.01105244 0.012968048
step: 300 train loss: 0.011645543 0.012963747
step: 350 train loss: 0.008458234 0.012960752
step: 400 train loss: 0.013525004 0.012955837
step: 450 train loss: 0.006917185 0.012950943
step: 500 train loss: 0.014710664 0.012946677
step: 550 train loss: 0.011887893 0.012942245
step: 600 train loss: 0.007472699 0.012937132
step: 650 train loss: 0.016391149 0.012934012
step: 700 train loss: 0.008303095 0.01293033
step: 750 train loss: 0.007185631 0.012926328
step: 800 train loss: 0.013903221 0.012922494
step: 850 train loss: 0.0036640712 0.012917538
step: 900 train loss: 0.011264472 0.012911692
step: 950 train loss: 0.009880703 0.012908305
step: 1000 train loss: 0.0064181234 0.012902871
step: 1050 train loss: 0.0076019415 0.012899527
step: 1100 train loss: 0.011322082 0.012895017
step: 1150 train loss: 0.010230213 0.0128900865
step: 1200 train loss: 0.012778629 0.01288649
step: 1250 train loss: 0.009355522 0.012881721
step: 1300 train loss: 0.012110647 0.012877173
step: 1350 train loss: 0.007416396 0.012872777
step: 1400 train loss: 0.013550707 0.012869198
step: 1450 train loss: 0.012119142 0.012863527
step: 1500 train loss: 0.01403604 0.012859978
step: 1550 train loss: 0.00914213 0.012855536
step: 1600 train loss: 0.012544399 0.012851346
step: 1650 train loss: 0.007824699 0.012846972
step: 1700 train loss: 0.0047195787 0.012842342
step: 1750 train loss: 0.0082938075 0.012838465
step: 1800 train loss: 0.0071470016 0.012834547
step: 1850 train loss: 0.018805068 0.012830818
step: 1900 train loss: 0.015087773 0.012827233
step: 1950 train loss: 0.008751391 0.012823375
step: 2000 train loss: 0.009249121 0.012818922
step: 2050 train loss: 0.0074882056 0.012815256
step: 2100 train loss: 0.004860754 0.012809717
step: 2150 train loss: 0.0076593617 0.012804433
step: 2200 train loss: 0.016526975 0.012799163
step: 2250 train loss: 0.009246679 0.012794275
step: 2300 train loss: 0.010252006 0.012790224
step: 2350 train loss: 0.0073328707 0.012786819
step: 2400 train loss: 0.0073924437 0.012782792
step: 2450 train loss: 0.009136946 0.012778485
started to evaluate
ratio 0
ratio 1
ratio 2
ratio 3
tensor([[0.7703]], device='cuda:0') tensor(0.5447)
tensor([[0.6865]], device='cuda:0') tensor(0.8603)
tensor([[0.6434]], device='cuda:0') tensor(0.5890)
error: tensor(0.2422)
tensor(399.8591)
Epoch number :  13
-- "train" loss 0.005966 -- "valid" loss 399.9
training epoch: 14
step: 0 train loss: 0.012194897 0.012774569
step: 50 train loss: 0.01240078 0.012770596
step: 100 train loss: 0.00702757 0.012766551
step: 150 train loss: 0.007479047 0.01276231
step: 200 train loss: 0.015788585 0.012759085
step: 250 train loss: 0.003121836 0.012755393
step: 300 train loss: 0.008123436 0.012750386
step: 350 train loss: 0.008755487 0.012745271
step: 400 train loss: 0.009858478 0.012741024
step: 450 train loss: 0.010732014 0.012736352
step: 500 train loss: 0.009475042 0.012732297
step: 550 train loss: 0.009676039 0.012728703
step: 600 train loss: 0.012561349 0.012723856
step: 650 train loss: 0.012367826 0.012719546
step: 700 train loss: 0.005714606 0.012714921
step: 750 train loss: 0.020587098 0.012710664
step: 800 train loss: 0.00968889 0.012707677
step: 850 train loss: 0.006031478 0.012703569
step: 900 train loss: 0.007703157 0.012698174
step: 950 train loss: 0.008894152 0.012694806
step: 1000 train loss: 0.0074742874 0.0126915155
step: 1050 train loss: 0.009071418 0.012687396
step: 1100 train loss: 0.008603131 0.012682916
step: 1150 train loss: 0.007851051 0.012679051
step: 1200 train loss: 0.0064324774 0.0126757715
step: 1250 train loss: 0.019971091 0.012673051
step: 1300 train loss: 0.010026849 0.012668629
step: 1350 train loss: 0.009801891 0.012664349
Traceback (most recent call last):
  File "D:\battery\main.py", line 196, in <module>
    model, train_loss, valid_loss, total_loss = trainer.train(train_loader, valid_loader, relationmodel=relationmodel, encoder=encoder, wandb=wandb)
  File "D:\battery\utils.py", line 325, in train
    all_scores = F.softmax(all_scores, dim=0)
  File "C:\Users\admin\anaconda3\envs\battery\lib\site-packages\torch\nn\functional.py", line 1841, in softmax
    ret = input.softmax(dim)
KeyboardInterrupt