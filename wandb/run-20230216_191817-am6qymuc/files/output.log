
(79923, 100, 13) (79923, 3) (220, 100, 13) (220, 3)
training epoch: 0
step: 0 train loss: 0.020461714 0.020461714
step: 50 train loss: 0.015068835 0.021425724
step: 100 train loss: 0.010854812 0.019618087
step: 150 train loss: 0.011890135 0.01835689
step: 200 train loss: 0.014596006 0.017705776
step: 250 train loss: 0.02258938 0.017143052
step: 300 train loss: 0.0146174785 0.016667597
step: 350 train loss: 0.017228577 0.016465055
step: 400 train loss: 0.017288368 0.016285112
step: 450 train loss: 0.014064846 0.01602643
step: 500 train loss: 0.016151484 0.01596546
step: 550 train loss: 0.008633962 0.01585095
step: 600 train loss: 0.011869678 0.015700897
step: 650 train loss: 0.01628467 0.015590427
step: 700 train loss: 0.011154007 0.015519141
step: 750 train loss: 0.00735102 0.015394162
step: 800 train loss: 0.017902005 0.015286248
step: 850 train loss: 0.0190132 0.01514249
step: 900 train loss: 0.0074889003 0.015007536
step: 950 train loss: 0.017688703 0.014926875
step: 1000 train loss: 0.014571998 0.014849644
step: 1050 train loss: 0.013970698 0.014810374
step: 1100 train loss: 0.017306155 0.014753908
step: 1150 train loss: 0.011370863 0.014631389
step: 1200 train loss: 0.016652184 0.014593199
step: 1250 train loss: 0.011495936 0.01447824
step: 1300 train loss: 0.016038967 0.014432718
step: 1350 train loss: 0.0111867385 0.014380579
step: 1400 train loss: 0.012896521 0.0142909
step: 1450 train loss: 0.008973805 0.014219514
step: 1500 train loss: 0.0121838 0.0141842235
step: 1550 train loss: 0.0059607113 0.014118353
step: 1600 train loss: 0.010092319 0.014050729
step: 1650 train loss: 0.016159393 0.014030533
step: 1700 train loss: 0.010263669 0.014012625
step: 1750 train loss: 0.012466955 0.013950611
step: 1800 train loss: 0.01492774 0.013896579
step: 1850 train loss: 0.009618437 0.013856836
step: 1900 train loss: 0.014981952 0.013833266
step: 1950 train loss: 0.009044901 0.013819413
step: 2000 train loss: 0.017877633 0.013787472
step: 2050 train loss: 0.008123707 0.013751068
step: 2100 train loss: 0.020596901 0.013789373
step: 2150 train loss: 0.01828597 0.0138393575
step: 2200 train loss: 0.011189729 0.01383211
step: 2250 train loss: 0.010160894 0.013793254
step: 2300 train loss: 0.013551745 0.01375483
step: 2350 train loss: 0.008930689 0.013756481
step: 2400 train loss: 0.013614807 0.013746847
step: 2450 train loss: 0.012400238 0.013729276
started to evaluate
ratio 0
ratio 1
ratio 2
ratio 3
tensor([[0.6373]], device='cuda:0') tensor(0.5447)
tensor([[0.6175]], device='cuda:0') tensor(0.8603)
tensor([[0.6659]], device='cuda:0') tensor(0.5890)
error: tensor(0.2576)
tensor(412.9239)
Epoch number :  0
-- "train" loss 0.02244 -- "valid" loss 412.9
training epoch: 1
step: 0 train loss: 0.010433388 0.013718026
step: 50 train loss: 0.011371243 0.013691903
step: 100 train loss: 0.010601902 0.013660813
step: 150 train loss: 0.012776676 0.013629189
step: 200 train loss: 0.0106283715 0.013603999
step: 250 train loss: 0.012513933 0.0135857705
step: 300 train loss: 0.007660555 0.013612267
step: 350 train loss: 0.014724757 0.013591329
step: 400 train loss: 0.023126151 0.013570195
step: 450 train loss: 0.008550705 0.013543107
step: 500 train loss: 0.016908504 0.013576048
step: 550 train loss: 0.011025598 0.013615624
step: 600 train loss: 0.011078178 0.013648107
step: 650 train loss: 0.020030133 0.013660604
step: 700 train loss: 0.016398257 0.0136612905
step: 750 train loss: 0.015178114 0.013648181
step: 800 train loss: 0.01185445 0.013623949
step: 850 train loss: 0.011369753 0.013593055
step: 900 train loss: 0.013579987 0.013568271
step: 950 train loss: 0.014122012 0.013541097
step: 1000 train loss: 0.01565673 0.013515446
